{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Logistic Function\n",
    "\n",
    "At its core, logistic regression is about making predictions for binary outcomes (Yes/No, 0/1, etc.). The key formula we use is called the **logistic function** or **sigmoid function**, which maps any real number into a range between 0 and 1.\n"
   ],
   "id": "753f921e211a711b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-21T03:20:09.348418Z",
     "start_time": "2024-09-21T03:20:09.343107Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.diagnosis"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T02:54:01.868717Z",
     "start_time": "2024-09-21T02:54:01.856803Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "4ec71f4040b3b4c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T02:54:33.136340Z",
     "start_time": "2024-09-21T02:54:33.132578Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "a2fc0d349c114542",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T03:18:03.679354Z",
     "start_time": "2024-09-21T03:18:03.676395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up sigmoid \n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1/(1 + np.exp(-z))"
   ],
   "id": "774b6aded9475098",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T03:18:04.114488Z",
     "start_time": "2024-09-21T03:18:04.112410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def log_loss(y, y_hat):\n",
    "    return -np.mean(\n",
    "        y*np.log(y_hat) + (1-y)*np.log(1-y_hat)\n",
    "    )"
   ],
   "id": "2847a3a2dd199a9d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T03:18:04.399060Z",
     "start_time": "2024-09-21T03:18:04.396718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(X, w, b):\n",
    "    z = np.dot(X, w) + b\n",
    "    return sigmoid(z)"
   ],
   "id": "6e5548f1312d1eae",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T03:18:04.721668Z",
     "start_time": "2024-09-21T03:18:04.717680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_descent(X, y, w, b, learning_rate, epochs):\n",
    "    m = len(y)\n",
    "    for epoch in range(epochs):\n",
    "        # make prediction\n",
    "        y_hat = predict(X, w, b)\n",
    "        \n",
    "        dw = np.dot(\n",
    "            X.T, (y_hat - y)\n",
    "        )/m\n",
    "        db = np.mean(y_hat - y)\n",
    "        \n",
    "        # Step 3: Update weights\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "        \n",
    "        # Step 4: Calculate and print the log-loss for monitoring\n",
    "        if epoch % 100 == 0:\n",
    "            loss = log_loss(y, y_hat)  # Call the log-loss function here\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "            \n",
    "    return w, b\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ],
   "id": "3f5b5882939955f6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T03:18:05.078319Z",
     "start_time": "2024-09-21T03:18:05.055242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example data (replace with real data)\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])  # 4 training examples, 2 features\n",
    "y = np.array([0, 0, 1, 1])  # Labels\n",
    "\n",
    "# Initialize weights\n",
    "w = np.zeros(X.shape[1])\n",
    "b = 0\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# Train the model\n",
    "w, b = gradient_descent(X, y, w, b, learning_rate, epochs)\n",
    "\n",
    "# Final loss after training\n",
    "y_hat_train = predict(X, w, b)  # Predictions for the training data\n",
    "final_loss = log_loss(y, y_hat_train)  # Calculate the final log-loss\n",
    "print(f'Final training loss: {final_loss}')\n"
   ],
   "id": "42733f4390682e44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931471805599453\n",
      "Epoch 100, Loss: 0.43544836419731786\n",
      "Epoch 200, Loss: 0.33167741153496816\n",
      "Epoch 300, Loss: 0.27285680583235167\n",
      "Epoch 400, Loss: 0.23497203343834544\n",
      "Epoch 500, Loss: 0.20828031859877386\n",
      "Epoch 600, Loss: 0.1882522009069065\n",
      "Epoch 700, Loss: 0.17252517074513768\n",
      "Epoch 800, Loss: 0.15975036523409938\n",
      "Epoch 900, Loss: 0.1491010336869133\n",
      "Final training loss: 0.14004100260740557\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T03:20:32.454780Z",
     "start_time": "2024-09-21T03:20:32.445076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Assuming your dataframe is stored in `df`\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Convert diagnosis to binary (0 = Benign, 1 = Malignant)\n",
    "df['diagnosis'] = df['diagnosis'].map({'B': 0, 'M': 1})\n",
    "\n",
    "# Step 3: Select features (the mean values) and the target\n",
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean',\n",
    "        'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', \n",
    "        'fractal_dimension_mean']]\n",
    "\n",
    "y = df['diagnosis']\n",
    "\n",
    "# Step 4: Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Feature scaling (Standardize the data)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ],
   "id": "f782ecf44e3b59db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "564    1\n",
       "565    1\n",
       "566    1\n",
       "567    1\n",
       "568    0\n",
       "Name: diagnosis, Length: 569, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T03:20:42.355227Z",
     "start_time": "2024-09-21T03:20:42.317801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Step 1: Initialize weights and bias\n",
    "n_features = X_train.shape[1]  # Number of features\n",
    "w = np.zeros(n_features)\n",
    "b = 0\n",
    "\n",
    "# Step 2: Train the model using gradient descent\n",
    "learning_rate = 0.01  # You can adjust this\n",
    "epochs = 1000  # You can adjust the number of epochs\n",
    "w, b = gradient_descent(X_train, y_train.to_numpy(), w, b, 0.01, epochs)\n",
    "\n",
    "# Step 3: Make predictions on the test set\n",
    "y_test_pred = predict(X_test, w, b)\n",
    "\n",
    "# Convert predicted probabilities to binary outcomes (0 or 1)\n",
    "y_test_pred_labels = np.where(y_test_pred >= 0.5, 1, 0)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    return correct_predictions / len(y_true)\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    predicted_positives = np.sum(y_pred == 1)\n",
    "    return true_positives / predicted_positives if predicted_positives != 0 else 0\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    actual_positives = np.sum(y_true == 1)\n",
    "    return true_positives / actual_positives if actual_positives != 0 else 0\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred_labels)\n",
    "precision = precision_score(y_test, y_test_pred_labels)\n",
    "recall = recall_score(y_test, y_test_pred_labels)\n",
    "f1 = f1_score(y_test, y_test_pred_labels)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n"
   ],
   "id": "ba78dd471c95fa9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931471805599453\n",
      "Epoch 100, Loss: 0.3653157814022778\n",
      "Epoch 200, Loss: 0.28526122055756853\n",
      "Epoch 300, Loss: 0.24875296603947514\n",
      "Epoch 400, Loss: 0.22762535543133128\n",
      "Epoch 500, Loss: 0.21373782607957373\n",
      "Epoch 600, Loss: 0.2038541883084372\n",
      "Epoch 700, Loss: 0.19642666105741455\n",
      "Epoch 800, Loss: 0.1906190975599504\n",
      "Epoch 900, Loss: 0.18593896377366204\n",
      "Accuracy: 0.956140350877193\n",
      "Precision: 0.975\n",
      "Recall: 0.9069767441860465\n",
      "F1-Score: 0.9397590361445783\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14174714ecbd5c7f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
